{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWConvblock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, size):\n",
    "        super(DWConvblock, self).__init__()\n",
    "        self.size = size\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.block =  nn.Sequential(nn.Conv2d(output_channels, output_channels, size, 1, 2, groups = output_channels, bias = False),\n",
    "                                    nn.BatchNorm2d(output_channels),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "      \n",
    "                                    nn.Conv2d(output_channels, output_channels, 1, 1, 0, bias = False),\n",
    "                                    nn.BatchNorm2d(output_channels),\n",
    "                                    \n",
    "                                    nn.Conv2d(output_channels, output_channels, size, 1, 2, groups = output_channels, bias = False),\n",
    "                                    nn.BatchNorm2d(output_channels ),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "      \n",
    "                                    nn.Conv2d(output_channels, output_channels, 1, 1, 0, bias = False),\n",
    "                                    nn.BatchNorm2d(output_channels),\n",
    "                                    )\n",
    "                                    \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "class LightFPN(nn.Module):\n",
    "    def __init__(self, input2_depth, input3_depth, out_depth):\n",
    "        super(LightFPN, self).__init__()\n",
    "\n",
    "        self.conv1x1_2 = nn.Sequential(nn.Conv2d(input2_depth, out_depth, 1, 1, 0, bias = False),\n",
    "                                       nn.BatchNorm2d(out_depth),\n",
    "                                       nn.ReLU(inplace=True)\n",
    "                                       )\n",
    "\n",
    "        self.conv1x1_3 = nn.Sequential(nn.Conv2d(input3_depth, out_depth, 1, 1, 0, bias = False),\n",
    "                                       nn.BatchNorm2d(out_depth),\n",
    "                                       nn.ReLU(inplace=True)\n",
    "                                       )\n",
    "        \n",
    "        self.cls_head_2 = DWConvblock(input2_depth, out_depth, 5)\n",
    "        self.reg_head_2 = DWConvblock(input2_depth, out_depth, 5)\n",
    "        \n",
    "        self.reg_head_3 = DWConvblock(input3_depth, out_depth, 5)\n",
    "        self.cls_head_3 = DWConvblock(input3_depth, out_depth, 5)\n",
    "\n",
    "    def forward(self, C2, C3):\n",
    "        S3 = self.conv1x1_3(C3)\n",
    "        cls_3 = self.cls_head_3(S3)\n",
    "        obj_3 = cls_3\n",
    "        reg_3 = self.reg_head_3(S3)\n",
    "\n",
    "        P2 = F.interpolate(C3, scale_factor=2)\n",
    "        P2 = torch.cat((P2, C2),1)\n",
    "        S2 = self.conv1x1_2(P2)\n",
    "        cls_2 = self.cls_head_2(S2)\n",
    "        obj_2 = cls_2\n",
    "        reg_2 = self.reg_head_2(S2)\n",
    "\n",
    "        return  cls_2, obj_2, reg_2, cls_3, obj_3, reg_3\n",
    "\n",
    "class ShuffleV2Block(nn.Module):\n",
    "    def __init__(self, inp, oup, mid_channels, *, ksize, stride):\n",
    "        super(ShuffleV2Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.mid_channels = mid_channels\n",
    "        self.ksize = ksize\n",
    "        pad = ksize // 2\n",
    "        self.pad = pad\n",
    "        self.inp = inp\n",
    "\n",
    "        outputs = oup - inp\n",
    "\n",
    "        branch_main = [\n",
    "            # pw\n",
    "            nn.Conv2d(inp, mid_channels, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(mid_channels, mid_channels, ksize, stride, pad, groups=mid_channels, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(mid_channels, outputs, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(outputs),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.branch_main = nn.Sequential(*branch_main)\n",
    "\n",
    "        if stride == 2:\n",
    "            branch_proj = [\n",
    "                # dw\n",
    "                nn.Conv2d(inp, inp, ksize, stride, pad, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(inp, inp, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            self.branch_proj = nn.Sequential(*branch_proj)\n",
    "        else:\n",
    "            self.branch_proj = None\n",
    "\n",
    "    def forward(self, old_x):\n",
    "        if self.stride==1:\n",
    "            x_proj, x = self.channel_shuffle(old_x)\n",
    "            return torch.cat((x_proj, self.branch_main(x)), 1)\n",
    "        elif self.stride==2:\n",
    "            x_proj = old_x\n",
    "            x = old_x\n",
    "            return torch.cat((self.branch_proj(x_proj), self.branch_main(x)), 1)\n",
    "\n",
    "    def channel_shuffle(self, x):\n",
    "        batchsize, num_channels, height, width = x.data.size()\n",
    "        assert (num_channels % 4 == 0)\n",
    "        x = x.reshape(batchsize * num_channels // 2, 2, height * width)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x.reshape(2, -1, num_channels // 2, height, width)\n",
    "        return x[0], x[1]\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    def __init__(self, stage_out_channels, load_param):\n",
    "        super(ShuffleNetV2, self).__init__()\n",
    "\n",
    "        self.stage_repeats = [4, 8, 4]\n",
    "        self.stage_out_channels = stage_out_channels\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = self.stage_out_channels[1]\n",
    "        self.first_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(input_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        stage_names = [\"stage2\", \"stage3\", \"stage4\"]\n",
    "        for idxstage in range(len(self.stage_repeats)):\n",
    "            numrepeat = self.stage_repeats[idxstage]\n",
    "            output_channel = self.stage_out_channels[idxstage+2]\n",
    "            stageSeq = []\n",
    "            for i in range(numrepeat):\n",
    "                if i == 0:\n",
    "                    stageSeq.append(ShuffleV2Block(input_channel, output_channel, \n",
    "                                                mid_channels=output_channel // 2, ksize=3, stride=2))\n",
    "                else:\n",
    "                    stageSeq.append(ShuffleV2Block(input_channel // 2, output_channel, \n",
    "                                                mid_channels=output_channel // 2, ksize=3, stride=1))\n",
    "                input_channel = output_channel\n",
    "            setattr(self, stage_names[idxstage], nn.Sequential(*stageSeq))\n",
    "        \n",
    "        if load_param == False:\n",
    "            self._initialize_weights()\n",
    "        else:\n",
    "            print(\"load param...\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        C1 = self.stage2(x)\n",
    "        C2 = self.stage3(C1)\n",
    "        C3 = self.stage4(C2)\n",
    "\n",
    "        return C2, C3\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        print(\"initialize_weights...\")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.load_state_dict(torch.load(\"./backbone.pth\", map_location=device), strict = True)\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, classes, anchor_num, load_param, export_onnx = False):\n",
    "        super(Detector, self).__init__()\n",
    "        out_depth = 72\n",
    "        stage_out_channels = [-1, 24, 48, 96, 192]\n",
    "\n",
    "        self.export_onnx = export_onnx\n",
    "        self.backbone = ShuffleNetV2(stage_out_channels, load_param)\n",
    "        self.fpn = LightFPN(stage_out_channels[-2] + stage_out_channels[-1], stage_out_channels[-1], out_depth)\n",
    "\n",
    "        self.output_reg_layers = nn.Conv2d(out_depth, 4 * anchor_num, 1, 1, 0, bias=True)\n",
    "        self.output_obj_layers = nn.Conv2d(out_depth, anchor_num, 1, 1, 0, bias=True)\n",
    "        self.output_cls_layers = nn.Conv2d(out_depth, classes, 1, 1, 0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        C2, C3 = self.backbone(x)\n",
    "        cls_2, obj_2, reg_2, cls_3, obj_3, reg_3 = self.fpn(C2, C3)\n",
    "        \n",
    "        out_reg_2 = self.output_reg_layers(reg_2)\n",
    "        out_obj_2 = self.output_obj_layers(obj_2)\n",
    "        out_cls_2 = self.output_cls_layers(cls_2)\n",
    "\n",
    "        out_reg_3 = self.output_reg_layers(reg_3)\n",
    "        out_obj_3 = self.output_obj_layers(obj_3)\n",
    "        out_cls_3 = self.output_cls_layers(cls_3)\n",
    "        \n",
    "        if self.export_onnx:\n",
    "            out_reg_2 = out_reg_2.sigmoid()\n",
    "            out_obj_2 = out_obj_2.sigmoid()\n",
    "            out_cls_2 = F.softmax(out_cls_2, dim = 1)\n",
    "\n",
    "            out_reg_3 = out_reg_3.sigmoid()\n",
    "            out_obj_3 = out_obj_3.sigmoid()\n",
    "            out_cls_3 = F.softmax(out_cls_3, dim = 1)\n",
    "\n",
    "            print(\"export onnx ...\")\n",
    "            return torch.cat((out_reg_2, out_obj_2, out_cls_2), 1).permute(0, 2, 3, 1), \\\n",
    "                   torch.cat((out_reg_3, out_obj_3, out_cls_3), 1).permute(0, 2, 3, 1)  \n",
    "\n",
    "        else:\n",
    "            return out_reg_2, out_obj_2, out_cls_2, out_reg_3, out_obj_3, out_cls_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(h, w, device):\n",
    "    hv, wv = torch.meshgrid([torch.arange(h), torch.arange(w)])\n",
    "    return torch.stack((wv, hv), 2).repeat(1,1,3).reshape(h, w, 3, -1).to(device)\n",
    "\n",
    "def handel_preds(preds, device):\n",
    "    #加载anchor配置\n",
    "    # anchors = np.array(cfg[\"anchors\"])\n",
    "    anchors = np.array(31.67,166.38, 46.77,209.52, 63.65,253.63, 83.14,292.26, 105.64,333.59, 138.17,346.51)\n",
    "    anchors = torch.from_numpy(anchors.reshape(len(preds) // 3, 3, 2)).to(device)\n",
    "\n",
    "    output_bboxes = []\n",
    "    layer_index = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "    for i in range(len(preds) // 3):\n",
    "        bacth_bboxes = []\n",
    "        reg_preds = preds[i * 3]\n",
    "        obj_preds = preds[(i * 3) + 1]\n",
    "        cls_preds = preds[(i * 3) + 2]\n",
    "\n",
    "        for r, o, c in zip(reg_preds, obj_preds, cls_preds):\n",
    "            r = r.permute(1, 2, 0)\n",
    "            r = r.reshape(r.shape[0], r.shape[1], 3, -1)\n",
    "\n",
    "            o = o.permute(1, 2, 0)\n",
    "            o = o.reshape(o.shape[0], o.shape[1], 3, -1)\n",
    "\n",
    "            c = c.permute(1, 2, 0)\n",
    "            c = c.reshape(c.shape[0],c.shape[1], 1, c.shape[2])\n",
    "            c = c.repeat(1, 1, 3, 1)\n",
    "\n",
    "            anchor_boxes = torch.zeros(r.shape[0], r.shape[1], r.shape[2], r.shape[3] + c.shape[3] + 1)\n",
    "\n",
    "            #计算anchor box的cx, cy\n",
    "            grid = make_grid(r.shape[0], r.shape[1], device)\n",
    "            stride = 352 /  r.shape[0]\n",
    "            anchor_boxes[:, :, :, :2] = ((r[:, :, :, :2].sigmoid() * 2. - 0.5) + grid) * stride\n",
    "\n",
    "            #计算anchor box的w, h\n",
    "            anchors_cfg = anchors[i]\n",
    "            anchor_boxes[:, :, :, 2:4] = (r[:, :, :, 2:4].sigmoid() * 2) ** 2 * anchors_cfg # wh\n",
    "\n",
    "            #计算obj分数\n",
    "            anchor_boxes[:, :, :, 4] = o[:, :, :, 0].sigmoid()\n",
    "\n",
    "            #计算cls分数\n",
    "            anchor_boxes[:, :, :, 5:] = F.softmax(c[:, :, :, :], dim = 3)\n",
    "\n",
    "            #torch tensor 转为 numpy array\n",
    "            anchor_boxes = anchor_boxes.cpu().detach().numpy() \n",
    "            bacth_bboxes.append(anchor_boxes)     \n",
    "\n",
    "        #n, anchor num, h, w, box => n, (anchor num*h*w), box\n",
    "        bacth_bboxes = torch.from_numpy(np.array(bacth_bboxes))\n",
    "        bacth_bboxes = bacth_bboxes.view(bacth_bboxes.shape[0], -1, bacth_bboxes.shape[-1]) \n",
    "\n",
    "        output_bboxes.append(bacth_bboxes)    \n",
    "        \n",
    "    #merge\n",
    "    output = torch.cat(output_bboxes, 1)\n",
    "            \n",
    "    return output\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "def non_max_suppression(prediction, conf_thres=0.3, iou_thres=0.45, classes=None):\n",
    "    \"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "\n",
    "    # Settings\n",
    "    # (pixels) minimum and maximum box width and height\n",
    "    max_wh = 4096\n",
    "    max_det = 300  # maximum number of detections per image\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 1.0  # seconds to quit after\n",
    "    multi_label = nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6), device=\"cpu\")] * prediction.shape[0]\n",
    "\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[x[..., 4] > conf_thres]  # confidence\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            # sort by confidence\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * max_wh  # classes\n",
    "        # boxes (offset by class), scores\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "\n",
    "        output[xi] = x[i].detach().cpu()\n",
    "\n",
    "        if (time.time() - t) > time_limit:\n",
    "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # Specify training configuration file\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', type=str, default='', \n",
    "                        help='The path of the .pth model to be transformed')\n",
    "    parser.add_argument('--input_dir', type=str, default='', \n",
    "                        help='Directory of input images')\n",
    "    parser.add_argument('--output_dir', type=str, default='output', \n",
    "                        help='Directory to save result images')\n",
    "    parser.add_argument('--csv_file', type=str, default='results.csv', \n",
    "                        help='CSV file to save results')\n",
    "    \n",
    "    opt = parser.parse_args()\n",
    "    assert os.path.exists(opt.weights), \"Please specify the correct model path\"\n",
    "    assert os.path.exists(opt.input_dir), \"Please specify a valid input directory\"\n",
    "    os.makedirs(opt.output_dir, exist_ok=True)  # Create output directory if not exists\n",
    "\n",
    "    # Load the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Detector(1, 3, True).to(device)\n",
    "    model.load_state_dict(torch.load(opt.weights, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Load label names\n",
    "    LABEL_NAMES = ['person']\n",
    "    \n",
    "    # Prepare CSV file\n",
    "    with open(opt.csv_file, mode='w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([\"Image\", \"Persons\", \"Average Confidence\"])\n",
    "\n",
    "        # Process each image in the directory\n",
    "        for img_file in os.listdir(opt.input_dir):\n",
    "            img_path = os.path.join(opt.input_dir, img_file)\n",
    "            ori_img = cv2.imread(img_path)\n",
    "            if ori_img is None:\n",
    "                # print(f\"Skipping file {img_file} (not an image)\")\n",
    "                continue\n",
    "\n",
    "            # Data preprocessing\n",
    "            res_img = cv2.resize(ori_img, (352, 352), interpolation=cv2.INTER_LINEAR)\n",
    "            img = res_img.reshape(1, 352, 352, 3)\n",
    "            img = torch.from_numpy(img.transpose(0, 3, 1, 2)).to(device).float() / 255.0\n",
    "\n",
    "            # Model inference\n",
    "            start = time.perf_counter()\n",
    "            preds = model(img)\n",
    "            end = time.perf_counter()\n",
    "            inference_time = (end - start) * 1000.0\n",
    "            print(f\"{img_file} - Forward time: {inference_time:.2f} ms\")\n",
    "\n",
    "            # Post-process predictions\n",
    "            output = handel_preds(preds, device)\n",
    "            output_boxes = non_max_suppression(output, conf_thres=0.3, iou_thres=0.4)\n",
    "\n",
    "            h, w, _ = ori_img.shape\n",
    "            scale_h, scale_w = h / 352, w / 352 \n",
    "\n",
    "            person_count = 0\n",
    "            confidence_scores = []\n",
    "\n",
    "            # Draw bounding boxes and collect predictions for persons\n",
    "            for box in output_boxes[0]:\n",
    "                box = box.tolist()\n",
    "                obj_score = box[4]\n",
    "                category = LABEL_NAMES[int(box[5])]\n",
    "                \n",
    "                # Check if the detected object is a person\n",
    "                if category.lower() == \"person\":\n",
    "                    person_count += 1\n",
    "                    confidence_scores.append(obj_score)\n",
    "                    \n",
    "                    x1, y1 = int(box[0] * scale_w), int(box[1] * scale_h)\n",
    "                    x2, y2 = int(box[2] * scale_w), int(box[3] * scale_h)\n",
    "\n",
    "                    cv2.rectangle(ori_img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "                    cv2.putText(ori_img, f'{obj_score:.2f}', (x1, y1 - 5), 0, 0.7, (0, 255, 0), 2)\t\n",
    "                    cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate average confidence score\n",
    "            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0\n",
    "\n",
    "            # Write result to CSV\n",
    "            csv_writer.writerow([img_file, person_count, f\"{avg_confidence:.2f}\"])\n",
    "\n",
    "            # Save result image\n",
    "            output_img_path = os.path.join(opt.output_dir, f\"{os.path.splitext(img_file)[0]}_result.png\")\n",
    "            cv2.imwrite(output_img_path, ori_img)\n",
    "\n",
    "    print(\"Processing complete. Results saved in the specified output directory and CSV file.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
