{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prep"
      ],
      "metadata": {
        "id": "R1Xd8tXJuv0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hampel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1m8FAaGvruw",
        "outputId": "21fe490f-aae2-4177-9a0e-56bfa7772d94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hampel\n",
            "  Downloading hampel-1.0.2.tar.gz (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from hampel) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from hampel) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->hampel) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->hampel) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->hampel) (1.16.0)\n",
            "Building wheels for collected packages: hampel\n",
            "  Building wheel for hampel (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hampel: filename=hampel-1.0.2-cp310-cp310-linux_x86_64.whl size=208988 sha256=04b2c1cee4e308bc71b0144393637e4f64e644f28197a2ca002378d65a22baf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/c3/3c/8a9f55c3de0b09faf919393d4c6f09b11b7421dcaa7243b820\n",
            "Successfully built hampel\n",
            "Installing collected packages: hampel\n",
            "Successfully installed hampel-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "2oSiAuAumncs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import argparse\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "from scipy.signal import savgol_filter\n",
        "from hampel import hampel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvoSSPDwn86R",
        "outputId": "9f0b1296-fbad-4a72-fb57-e5a6089eabd7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computer Vision section"
      ],
      "metadata": {
        "id": "N1cwSM1wux7x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wiDxO8gKmnct"
      },
      "outputs": [],
      "source": [
        "class DWConvblock(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, size):\n",
        "        super(DWConvblock, self).__init__()\n",
        "        self.size = size\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "        self.block =  nn.Sequential(nn.Conv2d(output_channels, output_channels, size, 1, 2, groups = output_channels, bias = False),\n",
        "                                    nn.BatchNorm2d(output_channels),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "\n",
        "                                    nn.Conv2d(output_channels, output_channels, 1, 1, 0, bias = False),\n",
        "                                    nn.BatchNorm2d(output_channels),\n",
        "\n",
        "                                    nn.Conv2d(output_channels, output_channels, size, 1, 2, groups = output_channels, bias = False),\n",
        "                                    nn.BatchNorm2d(output_channels ),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "\n",
        "                                    nn.Conv2d(output_channels, output_channels, 1, 1, 0, bias = False),\n",
        "                                    nn.BatchNorm2d(output_channels),\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class LightFPN(nn.Module):\n",
        "    def __init__(self, input2_depth, input3_depth, out_depth):\n",
        "        super(LightFPN, self).__init__()\n",
        "\n",
        "        self.conv1x1_2 = nn.Sequential(nn.Conv2d(input2_depth, out_depth, 1, 1, 0, bias = False),\n",
        "                                       nn.BatchNorm2d(out_depth),\n",
        "                                       nn.ReLU(inplace=True)\n",
        "                                       )\n",
        "\n",
        "        self.conv1x1_3 = nn.Sequential(nn.Conv2d(input3_depth, out_depth, 1, 1, 0, bias = False),\n",
        "                                       nn.BatchNorm2d(out_depth),\n",
        "                                       nn.ReLU(inplace=True)\n",
        "                                       )\n",
        "\n",
        "        self.cls_head_2 = DWConvblock(input2_depth, out_depth, 5)\n",
        "        self.reg_head_2 = DWConvblock(input2_depth, out_depth, 5)\n",
        "\n",
        "        self.reg_head_3 = DWConvblock(input3_depth, out_depth, 5)\n",
        "        self.cls_head_3 = DWConvblock(input3_depth, out_depth, 5)\n",
        "\n",
        "    def forward(self, C2, C3):\n",
        "        S3 = self.conv1x1_3(C3)\n",
        "        cls_3 = self.cls_head_3(S3)\n",
        "        obj_3 = cls_3\n",
        "        reg_3 = self.reg_head_3(S3)\n",
        "\n",
        "        P2 = F.interpolate(C3, scale_factor=2)\n",
        "        P2 = torch.cat((P2, C2),1)\n",
        "        S2 = self.conv1x1_2(P2)\n",
        "        cls_2 = self.cls_head_2(S2)\n",
        "        obj_2 = cls_2\n",
        "        reg_2 = self.reg_head_2(S2)\n",
        "\n",
        "        return  cls_2, obj_2, reg_2, cls_3, obj_3, reg_3\n",
        "\n",
        "class ShuffleV2Block(nn.Module):\n",
        "    def __init__(self, inp, oup, mid_channels, *, ksize, stride):\n",
        "        super(ShuffleV2Block, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        self.mid_channels = mid_channels\n",
        "        self.ksize = ksize\n",
        "        pad = ksize // 2\n",
        "        self.pad = pad\n",
        "        self.inp = inp\n",
        "\n",
        "        outputs = oup - inp\n",
        "\n",
        "        branch_main = [\n",
        "            # pw\n",
        "            nn.Conv2d(inp, mid_channels, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # dw\n",
        "            nn.Conv2d(mid_channels, mid_channels, ksize, stride, pad, groups=mid_channels, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(mid_channels, outputs, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(outputs),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        self.branch_main = nn.Sequential(*branch_main)\n",
        "\n",
        "        if stride == 2:\n",
        "            branch_proj = [\n",
        "                # dw\n",
        "                nn.Conv2d(inp, inp, ksize, stride, pad, groups=inp, bias=False),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(inp, inp, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            self.branch_proj = nn.Sequential(*branch_proj)\n",
        "        else:\n",
        "            self.branch_proj = None\n",
        "\n",
        "    def forward(self, old_x):\n",
        "        if self.stride==1:\n",
        "            x_proj, x = self.channel_shuffle(old_x)\n",
        "            return torch.cat((x_proj, self.branch_main(x)), 1)\n",
        "        elif self.stride==2:\n",
        "            x_proj = old_x\n",
        "            x = old_x\n",
        "            return torch.cat((self.branch_proj(x_proj), self.branch_main(x)), 1)\n",
        "\n",
        "    def channel_shuffle(self, x):\n",
        "        batchsize, num_channels, height, width = x.data.size()\n",
        "        assert (num_channels % 4 == 0)\n",
        "        x = x.reshape(batchsize * num_channels // 2, 2, height * width)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.reshape(2, -1, num_channels // 2, height, width)\n",
        "        return x[0], x[1]\n",
        "\n",
        "class ShuffleNetV2(nn.Module):\n",
        "    def __init__(self, stage_out_channels, load_param):\n",
        "        super(ShuffleNetV2, self).__init__()\n",
        "\n",
        "        self.stage_repeats = [4, 8, 4]\n",
        "        self.stage_out_channels = stage_out_channels\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = self.stage_out_channels[1]\n",
        "        self.first_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(input_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        stage_names = [\"stage2\", \"stage3\", \"stage4\"]\n",
        "        for idxstage in range(len(self.stage_repeats)):\n",
        "            numrepeat = self.stage_repeats[idxstage]\n",
        "            output_channel = self.stage_out_channels[idxstage+2]\n",
        "            stageSeq = []\n",
        "            for i in range(numrepeat):\n",
        "                if i == 0:\n",
        "                    stageSeq.append(ShuffleV2Block(input_channel, output_channel,\n",
        "                                                mid_channels=output_channel // 2, ksize=3, stride=2))\n",
        "                else:\n",
        "                    stageSeq.append(ShuffleV2Block(input_channel // 2, output_channel,\n",
        "                                                mid_channels=output_channel // 2, ksize=3, stride=1))\n",
        "                input_channel = output_channel\n",
        "            setattr(self, stage_names[idxstage], nn.Sequential(*stageSeq))\n",
        "\n",
        "        if load_param == False:\n",
        "            self._initialize_weights()\n",
        "        else:\n",
        "            print(\"load param...\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_conv(x)\n",
        "        x = self.maxpool(x)\n",
        "        C1 = self.stage2(x)\n",
        "        C2 = self.stage3(C1)\n",
        "        C3 = self.stage4(C2)\n",
        "\n",
        "        return C2, C3\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        print(\"initialize_weights...\")\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.load_state_dict(torch.load(\"./backbone.pth\", map_location=device), strict = True)\n",
        "\n",
        "class Detector(nn.Module):\n",
        "    def __init__(self, classes, anchor_num, load_param, export_onnx = False):\n",
        "        super(Detector, self).__init__()\n",
        "        out_depth = 72\n",
        "        stage_out_channels = [-1, 24, 48, 96, 192]\n",
        "\n",
        "        self.export_onnx = export_onnx\n",
        "        self.backbone = ShuffleNetV2(stage_out_channels, load_param)\n",
        "        self.fpn = LightFPN(stage_out_channels[-2] + stage_out_channels[-1], stage_out_channels[-1], out_depth)\n",
        "\n",
        "        self.output_reg_layers = nn.Conv2d(out_depth, 4 * anchor_num, 1, 1, 0, bias=True)\n",
        "        self.output_obj_layers = nn.Conv2d(out_depth, anchor_num, 1, 1, 0, bias=True)\n",
        "        self.output_cls_layers = nn.Conv2d(out_depth, classes, 1, 1, 0, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        C2, C3 = self.backbone(x)\n",
        "        cls_2, obj_2, reg_2, cls_3, obj_3, reg_3 = self.fpn(C2, C3)\n",
        "\n",
        "        out_reg_2 = self.output_reg_layers(reg_2)\n",
        "        out_obj_2 = self.output_obj_layers(obj_2)\n",
        "        out_cls_2 = self.output_cls_layers(cls_2)\n",
        "\n",
        "        out_reg_3 = self.output_reg_layers(reg_3)\n",
        "        out_obj_3 = self.output_obj_layers(obj_3)\n",
        "        out_cls_3 = self.output_cls_layers(cls_3)\n",
        "\n",
        "        if self.export_onnx:\n",
        "            out_reg_2 = out_reg_2.sigmoid()\n",
        "            out_obj_2 = out_obj_2.sigmoid()\n",
        "            out_cls_2 = F.softmax(out_cls_2, dim = 1)\n",
        "\n",
        "            out_reg_3 = out_reg_3.sigmoid()\n",
        "            out_obj_3 = out_obj_3.sigmoid()\n",
        "            out_cls_3 = F.softmax(out_cls_3, dim = 1)\n",
        "\n",
        "            print(\"export onnx ...\")\n",
        "            return torch.cat((out_reg_2, out_obj_2, out_cls_2), 1).permute(0, 2, 3, 1), \\\n",
        "                   torch.cat((out_reg_3, out_obj_3, out_cls_3), 1).permute(0, 2, 3, 1)\n",
        "\n",
        "        else:\n",
        "            return out_reg_2, out_obj_2, out_cls_2, out_reg_3, out_obj_3, out_cls_3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fNeGPh6Qmncv"
      },
      "outputs": [],
      "source": [
        "def make_grid(h, w, device):\n",
        "    hv, wv = torch.meshgrid([torch.arange(h), torch.arange(w)])\n",
        "    return torch.stack((wv, hv), 2).repeat(1,1,3).reshape(h, w, 3, -1).to(device)\n",
        "\n",
        "def handel_preds(preds, device):\n",
        "    #加载anchor配置\n",
        "    # anchors = np.array(cfg[\"anchors\"])\n",
        "    anchors = np.array([31.67,166.38, 46.77,209.52, 63.65,253.63, 83.14,292.26, 105.64,333.59, 138.17,346.51])\n",
        "    anchors = torch.from_numpy(anchors.reshape(len(preds) // 3, 3, 2)).to(device)\n",
        "\n",
        "    output_bboxes = []\n",
        "    layer_index = [0, 0, 0, 1, 1, 1]\n",
        "\n",
        "    for i in range(len(preds) // 3):\n",
        "        bacth_bboxes = []\n",
        "        reg_preds = preds[i * 3]\n",
        "        obj_preds = preds[(i * 3) + 1]\n",
        "        cls_preds = preds[(i * 3) + 2]\n",
        "\n",
        "        for r, o, c in zip(reg_preds, obj_preds, cls_preds):\n",
        "            r = r.permute(1, 2, 0)\n",
        "            r = r.reshape(r.shape[0], r.shape[1], 3, -1)\n",
        "\n",
        "            o = o.permute(1, 2, 0)\n",
        "            o = o.reshape(o.shape[0], o.shape[1], 3, -1)\n",
        "\n",
        "            c = c.permute(1, 2, 0)\n",
        "            c = c.reshape(c.shape[0],c.shape[1], 1, c.shape[2])\n",
        "            c = c.repeat(1, 1, 3, 1)\n",
        "\n",
        "            anchor_boxes = torch.zeros(r.shape[0], r.shape[1], r.shape[2], r.shape[3] + c.shape[3] + 1)\n",
        "\n",
        "            #计算anchor box的cx, cy\n",
        "            grid = make_grid(r.shape[0], r.shape[1], device)\n",
        "            stride = 352 /  r.shape[0]\n",
        "            anchor_boxes[:, :, :, :2] = ((r[:, :, :, :2].sigmoid() * 2. - 0.5) + grid) * stride\n",
        "\n",
        "            #计算anchor box的w, h\n",
        "            anchors_cfg = anchors[i]\n",
        "            anchor_boxes[:, :, :, 2:4] = (r[:, :, :, 2:4].sigmoid() * 2) ** 2 * anchors_cfg # wh\n",
        "\n",
        "            #计算obj分数\n",
        "            anchor_boxes[:, :, :, 4] = o[:, :, :, 0].sigmoid()\n",
        "\n",
        "            #计算cls分数\n",
        "            anchor_boxes[:, :, :, 5:] = F.softmax(c[:, :, :, :], dim = 3)\n",
        "\n",
        "            #torch tensor 转为 numpy array\n",
        "            anchor_boxes = anchor_boxes.cpu().detach().numpy()\n",
        "            bacth_bboxes.append(anchor_boxes)\n",
        "\n",
        "        #n, anchor num, h, w, box => n, (anchor num*h*w), box\n",
        "        bacth_bboxes = torch.from_numpy(np.array(bacth_bboxes))\n",
        "        bacth_bboxes = bacth_bboxes.view(bacth_bboxes.shape[0], -1, bacth_bboxes.shape[-1])\n",
        "\n",
        "        output_bboxes.append(bacth_bboxes)\n",
        "\n",
        "    #merge\n",
        "    output = torch.cat(output_bboxes, 1)\n",
        "\n",
        "    return output\n",
        "\n",
        "def xywh2xyxy(x):\n",
        "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
        "    y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
        "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
        "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
        "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
        "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
        "    return y\n",
        "\n",
        "def non_max_suppression(prediction, conf_thres=0.3, iou_thres=0.45, classes=None):\n",
        "    \"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n",
        "    Returns:\n",
        "         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n",
        "    \"\"\"\n",
        "\n",
        "    nc = prediction.shape[2] - 5  # number of classes\n",
        "\n",
        "    # Settings\n",
        "    # (pixels) minimum and maximum box width and height\n",
        "    max_wh = 4096\n",
        "    max_det = 300  # maximum number of detections per image\n",
        "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
        "    time_limit = 1.0  # seconds to quit after\n",
        "    multi_label = nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
        "\n",
        "    t = time.time()\n",
        "    output = [torch.zeros((0, 6), device=\"cpu\")] * prediction.shape[0]\n",
        "\n",
        "    for xi, x in enumerate(prediction):  # image index, image inference\n",
        "        # Apply constraints\n",
        "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
        "        x = x[x[..., 4] > conf_thres]  # confidence\n",
        "\n",
        "        # If none remain process next image\n",
        "        if not x.shape[0]:\n",
        "            continue\n",
        "\n",
        "        # Compute conf\n",
        "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
        "\n",
        "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "        box = xywh2xyxy(x[:, :4])\n",
        "\n",
        "        # Detections matrix nx6 (xyxy, conf, cls)\n",
        "        conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "        x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
        "\n",
        "        # Filter by class\n",
        "        if classes is not None:\n",
        "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
        "\n",
        "        # Check shape\n",
        "        n = x.shape[0]  # number of boxes\n",
        "        if not n:  # no boxes\n",
        "            continue\n",
        "        elif n > max_nms:  # excess boxes\n",
        "            # sort by confidence\n",
        "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
        "\n",
        "        # Batched NMS\n",
        "        c = x[:, 5:6] * max_wh  # classes\n",
        "        # boxes (offset by class), scores\n",
        "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
        "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
        "        if i.shape[0] > max_det:  # limit detections\n",
        "            i = i[:max_det]\n",
        "\n",
        "        output[xi] = x[i].detach().cpu()\n",
        "\n",
        "        if (time.time() - t) > time_limit:\n",
        "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
        "            break  # time limit exceeded\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WiFi Section"
      ],
      "metadata": {
        "id": "OqTr1_hQvCe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ESP32:\n",
        "    \"\"\"Parse ESP32 Wi-Fi Channel State Information (CSI) obtained using ESP32 CSI Toolkit by Hernandez and Bulut.\n",
        "    ESP32 CSI Toolkit: https://stevenmhernandez.github.io/ESP32-CSI-Tool/\n",
        "    \"\"\"\n",
        "\n",
        "    NULL_SUBCARRIERS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 64, 65, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 382, 383]\n",
        "\n",
        "    def __init__(self, csi_file):\n",
        "        self.csi_file = csi_file\n",
        "        self.__read_file()\n",
        "\n",
        "    def __read_file(self):\n",
        "        \"\"\"Read RAW CSI file (.csv) using Pandas and return a Pandas dataframe\n",
        "        \"\"\"\n",
        "        self.csi_df = pd.read_csv(self.csi_file)\n",
        "\n",
        "    def seek_file(self):\n",
        "        \"\"\"Seek RAW CSI file\n",
        "        \"\"\"\n",
        "        return self.csi_df\n",
        "\n",
        "    def filter_by_sig_mode(self, sig_mode):\n",
        "        \"\"\"Filter CSI data by signal mode\n",
        "        Args:\n",
        "            sig_mode (int):\n",
        "            0 : Non - High Throughput Signals (non-HT)\n",
        "            1 : HIgh Throughput Signals (HT)\n",
        "        \"\"\"\n",
        "        self.csi_df = self.csi_df.loc[self.csi_df['sig_mode'] == sig_mode]\n",
        "        return self\n",
        "\n",
        "    def get_csi(self):\n",
        "        \"\"\"Read CSI string as Numpy array\n",
        "\n",
        "        The CSI data collected by ESP32 contains channel frequency responses (CFR) represented by two signed bytes (imaginary, real) for each sub-carriers index\n",
        "        The length (bytes) of the CSI sequency depends on the CFR type\n",
        "        CFR consist of legacy long training field (LLTF), high-throughput LTF (HT-LTF), and space- time block code HT-LTF (STBC-HT-LTF)\n",
        "        Ref: https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/wifi.html#wi-fi-channel-state-information\n",
        "\n",
        "        NOTE: Not all 3 field may not be present (as represented in table and configuration)\n",
        "        \"\"\"\n",
        "        raw_csi_data = self.csi_df['CSI_DATA'].copy()\n",
        "        csi_data = np.array([np.fromstring(csi_datum.strip('[ ]'), dtype=int, sep = ' ') for csi_datum in raw_csi_data])\n",
        "        self.csi_data = csi_data\n",
        "        return self\n",
        "\n",
        "    # NOTE: Currently does not provide support for all signal subcarrier types\n",
        "    def remove_null_subcarriers(self):\n",
        "        \"\"\"Remove NULL subcarriers from CSI\n",
        "        \"\"\"\n",
        "\n",
        "        # Non-HT Signals (20 Mhz) - non STBC\n",
        "        if self.csi_data.shape[1] == 128:\n",
        "            remove_null_subcarriers = self.NULL_SUBCARRIERS[:24]\n",
        "        # HT Signals (40 Mhz) - non STBC\n",
        "        elif self.csi_data.shape[1] == 384:\n",
        "            remove_null_subcarriers = self.NULL_SUBCARRIERS\n",
        "        else:\n",
        "            return self\n",
        "\n",
        "        csi_data_T = self.csi_data.T\n",
        "        csi_data_T_clean = np.delete(csi_data_T, remove_null_subcarriers, 0)\n",
        "        csi_data_clean = csi_data_T_clean.T\n",
        "        self.csi_data = csi_data_clean\n",
        "\n",
        "        return self\n",
        "\n",
        "    def get_amplitude_from_csi(self):\n",
        "        \"\"\"Calculate the Amplitude (or Magnitude) from CSI\n",
        "        Ref: https://farside.ph.utexas.edu/teaching/315/Waveshtml/node88.html\n",
        "        \"\"\"\n",
        "        amplitude = np.array([np.sqrt(data[::2]**2 + data[1::2]**2) for data in self.csi_data])\n",
        "        self.amplitude = amplitude\n",
        "        return self\n",
        "\n",
        "    def get_phase_from_csi(self):\n",
        "        \"\"\"Calculate the Amplitude (or Magnitude) from CSI\n",
        "        Ref: https://farside.ph.utexas.edu/teaching/315/Waveshtml/node88.html\n",
        "        \"\"\"\n",
        "        phase = np.array([np.arctan2(data[::2], data[1::2]) for data in self.csi_data])\n",
        "        self.phase = phase\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y_SRVG_fvG23"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_data(data, window_size=200, overlap=50):\n",
        "    segmented_data = []\n",
        "    for i in range(0, data.shape[0] - window_size + 1, window_size - overlap):\n",
        "        window = data[i:i+window_size] if data.ndim == 1 else data[i:i+window_size, :]\n",
        "        segmented_data.append(window)\n",
        "    return segmented_data\n",
        "\n",
        "def extract_amplitude(raw_data):\n",
        "    csi_array = (\n",
        "        ESP32(raw_data)\n",
        "            .get_csi()\n",
        "            .remove_null_subcarriers()\n",
        "            .get_amplitude_from_csi()\n",
        "    )\n",
        "    amp_df = pd.DataFrame(csi_array.amplitude, index=None)\n",
        "    return amp_df\n",
        "\n",
        "def denoise_data(amp_df):\n",
        "    filtered_df = pd.DataFrame()\n",
        "    for col in amp_df.columns:\n",
        "        col_series = amp_df[col]\n",
        "        # Hampel filter\n",
        "        hampel_filtered = hampel(col_series, window_size=10)\n",
        "        # Savitzky-Golay filter\n",
        "        sg_filtered = savgol_filter(hampel_filtered.filtered_data, window_length=10, polyorder=3)\n",
        "        filtered_df[col] = sg_filtered\n",
        "    return filtered_df\n",
        "\n",
        "def extract_features(filtered_df_with_rssi):\n",
        "    features = {}\n",
        "    for i in range(filtered_df_with_rssi.shape[1] - 1): # Loop through each subcarrier\n",
        "      features[f'std_subcarrier_{i}'] = np.std(filtered_df_with_rssi[:, i]) # Standard deviation\n",
        "      features[f'mean_subcarrier_{i}'] = np.mean(filtered_df_with_rssi[:, i]) # The average amplitude value\n",
        "      features[f'max_subcarrier_{i}'] = np.max(filtered_df_with_rssi[:, i])\n",
        "      features[f'min_subcarrier_{i}'] = np.min(filtered_df_with_rssi[:, i])\n",
        "      features[f'qtu_subcarrier_{i}'] = np.percentile(filtered_df_with_rssi[:, i], 75) # Upper quartile\n",
        "      features[f'qtl_subcarrier_{i}'] = np.percentile(filtered_df_with_rssi[:, i], 25) # Lower quartile\n",
        "      features[f'iqr_subcarrier_{i}'] = features[f'qtu_subcarrier_{i}'] - features[f'qtl_subcarrier_{i}']\n",
        "      if i >= 2 and i <= 49:\n",
        "        diff = 0\n",
        "        for j in range(1,3):  # Ignore first and last two subcarriers\n",
        "            diff += np.sum(\n",
        "                np.abs(filtered_df_with_rssi[:, i] - filtered_df_with_rssi[:, i - j]) + np.abs(filtered_df_with_rssi[:, i + j] - filtered_df_with_rssi[:, i])\n",
        "          )\n",
        "        features[f'adj_subcarrier_{i-2}'] = diff\n",
        "\n",
        "    euclidean_distances = []\n",
        "    for i in range(1, filtered_df_with_rssi.shape[0]):  # Loop through packets starting from the second\n",
        "      distances = np.linalg.norm(filtered_df_with_rssi[i, :] - filtered_df_with_rssi[i-1, :], axis=0)\n",
        "      euclidean_distances.append(distances)\n",
        "\n",
        "    features['euc'] = np.median(euclidean_distances)\n",
        "    features['rss_std']= np.std(filtered_df_with_rssi[:, -1])\n",
        "    features = pd.DataFrame([features])\n",
        "    return features"
      ],
      "metadata": {
        "id": "plWMx7icwWXf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WiFi-Vision Testing"
      ],
      "metadata": {
        "id": "sjd5xR1Fu6Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load testing dataset"
      ],
      "metadata": {
        "id": "hncB2cjzx_gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csi_data(csi_path):\n",
        "  csi_df = pd.read_csv(csi_path)\n",
        "  rssi_col = csi_df['rssi']\n",
        "  raw_amp = extract_amplitude(csi_path)\n",
        "  filtered_amp = denoise_data(raw_amp)\n",
        "  filtered_amp['rssi'] = rssi_col.values[:len(filtered_amp)]\n",
        "\n",
        "  features_list = []\n",
        "  temp_df = filtered_amp.copy()\n",
        "  temp_np_array = np.array(temp_df) # Turn into numpy array for easier matrix calculation\n",
        "  segments = segment_data(temp_np_array)\n",
        "  print(f\"There are {len(segments)} segments to extract\")\n",
        "\n",
        "  for segment in segments:\n",
        "    features = extract_features(segment)\n",
        "    features_list.append(features)\n",
        "\n",
        "  features_df = pd.concat(features_list, ignore_index=True)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(features_df)\n",
        "  csi_dataset = scaler.transform(features_df)\n",
        "  return csi_dataset"
      ],
      "metadata": {
        "id": "nxuKNc4LyvTy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img_data(img_path):\n",
        "  image_filenames = os.listdir(img_path)\n",
        "  # Extract timestamps from filenames and sort them\n",
        "  timestamps = []\n",
        "\n",
        "  for filename in image_filenames:\n",
        "    timestamp_str = filename.replace(\"frame_\", \"\").replace(\".jpg\", \"\")\n",
        "    timestamps.append(float(timestamp_str))\n",
        "\n",
        "  timestamps = sorted(timestamps)\n",
        "  # Select images with a 2-second interval\n",
        "  selected_timestamps = []\n",
        "  previous_timestamp = None\n",
        "  for timestamp in timestamps:\n",
        "      if previous_timestamp is None or timestamp - previous_timestamp >= 2:\n",
        "          selected_timestamps.append(timestamp)\n",
        "          previous_timestamp = timestamp\n",
        "  print(len(selected_timestamps))\n",
        "  return selected_timestamps"
      ],
      "metadata": {
        "id": "RFRMToRxx-1-"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load models"
      ],
      "metadata": {
        "id": "OBoUSjdLzxw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csi_model(csi_model_path):\n",
        "  csi_model = tf.keras.models.load_model(csi_model_path)\n",
        "  print(csi_model.summary())\n",
        "  return csi_model"
      ],
      "metadata": {
        "id": "AbfG5RDOz1fb"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cv_model(weights_path, device):\n",
        "  # Load the model\n",
        "  cv_model = Detector(1, 3, True).to(device)\n",
        "  cv_model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "  cv_model.eval()\n",
        "  print(cv_model)\n",
        "  return cv_model"
      ],
      "metadata": {
        "id": "5E_8L0xx0mPp"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csi_model = load_csi_model('/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Models/WiCount_FE_DNNR_2days.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "V-vCJuzg5_IE",
        "outputId": "fe9fdece-d4b2-452a-a5f6-9c4cc02b7a38"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_120 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │         \u001b[38;5;34m415,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_121 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m500,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m50,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">415,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">500,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,899,865\u001b[0m (11.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,899,865</span> (11.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m966,621\u001b[0m (3.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">966,621</span> (3.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,933,244\u001b[0m (7.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,933,244</span> (7.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_model = load_cv_model('/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Models/yolof2-v4/yolofv2-nano-190-epoch-0.945714ap-model.pth')"
      ],
      "metadata": {
        "id": "O5UK6WcZ0whp",
        "outputId": "fddbcb43-459e-46a2-ef71-b978623882f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load param...\n",
            "Detector(\n",
            "  (backbone): ShuffleNetV2(\n",
            "    (first_conv): Sequential(\n",
            "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (stage2): Sequential(\n",
            "      (0): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
            "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "        (branch_proj): Sequential(\n",
            "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (3): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage3): Sequential(\n",
            "      (0): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "        (branch_proj): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (3): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (4): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (5): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (6): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (7): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage4): Sequential(\n",
            "      (0): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "        (branch_proj): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (3): ShuffleV2Block(\n",
            "        (branch_main): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (7): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fpn): LightFPN(\n",
            "    (conv1x1_2): Sequential(\n",
            "      (0): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv1x1_3): Sequential(\n",
            "      (0): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (cls_head_2): DWConvblock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (6): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (9): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_head_2): DWConvblock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (6): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (9): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_head_3): DWConvblock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (6): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (9): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_head_3): DWConvblock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
            "        (6): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (9): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output_reg_layers): Conv2d(72, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (output_obj_layers): Conv2d(72, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (output_cls_layers): Conv2d(72, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-94-3552eec4fb68>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cv_model.load_state_dict(torch.load(weights_path, map_location=device))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHSGwDs5mncw",
        "outputId": "b4dbfd24-3289-4a57-c825-dc47b526694e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85\n",
            "load param...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-b24979dd00e8>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frame_1728097171.6832385.jpg - Forward time: 53.56 ms\n",
            "frame_1728097173.7763522.jpg - Forward time: 39.11 ms\n",
            "frame_1728097175.8573422.jpg - Forward time: 26.85 ms\n",
            "frame_1728097177.9508202.jpg - Forward time: 30.60 ms\n",
            "frame_1728097180.0337336.jpg - Forward time: 27.24 ms\n",
            "frame_1728097182.1125855.jpg - Forward time: 28.19 ms\n",
            "frame_1728097184.1985004.jpg - Forward time: 36.35 ms\n",
            "frame_1728097186.2712324.jpg - Forward time: 30.22 ms\n",
            "frame_1728097188.3541796.jpg - Forward time: 29.99 ms\n",
            "frame_1728097190.4391413.jpg - Forward time: 28.31 ms\n",
            "frame_1728097192.5285933.jpg - Forward time: 30.93 ms\n",
            "frame_1728097194.6059685.jpg - Forward time: 24.45 ms\n",
            "frame_1728097196.701152.jpg - Forward time: 24.33 ms\n",
            "frame_1728097198.7897072.jpg - Forward time: 23.50 ms\n",
            "frame_1728097200.8785574.jpg - Forward time: 29.85 ms\n",
            "frame_1728097202.9462562.jpg - Forward time: 25.76 ms\n",
            "frame_1728097205.051112.jpg - Forward time: 44.45 ms\n",
            "frame_1728097207.1356993.jpg - Forward time: 36.82 ms\n",
            "frame_1728097209.2243829.jpg - Forward time: 23.54 ms\n",
            "frame_1728097211.3018258.jpg - Forward time: 24.98 ms\n",
            "frame_1728097213.3634632.jpg - Forward time: 23.21 ms\n",
            "frame_1728097215.4439578.jpg - Forward time: 23.69 ms\n",
            "frame_1728097217.5364642.jpg - Forward time: 23.51 ms\n",
            "frame_1728097219.6117573.jpg - Forward time: 24.14 ms\n",
            "frame_1728097221.6897655.jpg - Forward time: 24.21 ms\n",
            "frame_1728097223.7702143.jpg - Forward time: 41.55 ms\n",
            "frame_1728097225.860651.jpg - Forward time: 25.27 ms\n",
            "frame_1728097227.9164138.jpg - Forward time: 25.16 ms\n",
            "frame_1728097230.0035548.jpg - Forward time: 26.32 ms\n",
            "frame_1728097232.0977547.jpg - Forward time: 24.62 ms\n",
            "frame_1728097234.181138.jpg - Forward time: 26.64 ms\n",
            "frame_1728097236.2595227.jpg - Forward time: 25.28 ms\n",
            "frame_1728097238.342079.jpg - Forward time: 33.12 ms\n",
            "frame_1728097240.4237137.jpg - Forward time: 49.35 ms\n",
            "frame_1728097242.505569.jpg - Forward time: 24.36 ms\n",
            "frame_1728097244.57866.jpg - Forward time: 25.47 ms\n",
            "frame_1728097246.6594312.jpg - Forward time: 28.27 ms\n",
            "frame_1728097248.73816.jpg - Forward time: 26.69 ms\n",
            "frame_1728097250.8268137.jpg - Forward time: 40.19 ms\n",
            "frame_1728097252.8922708.jpg - Forward time: 33.49 ms\n",
            "frame_1728097254.9812827.jpg - Forward time: 49.99 ms\n",
            "frame_1728097257.0600407.jpg - Forward time: 40.32 ms\n",
            "frame_1728097259.1312296.jpg - Forward time: 29.21 ms\n",
            "frame_1728097261.2112072.jpg - Forward time: 26.77 ms\n",
            "frame_1728097263.301632.jpg - Forward time: 25.73 ms\n",
            "frame_1728097265.3811176.jpg - Forward time: 26.50 ms\n",
            "frame_1728097267.4747329.jpg - Forward time: 30.18 ms\n",
            "frame_1728097269.557824.jpg - Forward time: 44.72 ms\n",
            "frame_1728097271.6303477.jpg - Forward time: 35.52 ms\n",
            "frame_1728097273.7192578.jpg - Forward time: 26.69 ms\n",
            "frame_1728097275.7966597.jpg - Forward time: 27.34 ms\n",
            "frame_1728097277.8670175.jpg - Forward time: 26.42 ms\n",
            "frame_1728097279.9416366.jpg - Forward time: 37.55 ms\n",
            "frame_1728097282.031646.jpg - Forward time: 31.75 ms\n",
            "frame_1728097284.1123533.jpg - Forward time: 40.92 ms\n",
            "frame_1728097286.191295.jpg - Forward time: 45.09 ms\n",
            "frame_1728097288.2827063.jpg - Forward time: 43.36 ms\n",
            "frame_1728097290.3564138.jpg - Forward time: 24.54 ms\n",
            "frame_1728097292.4397023.jpg - Forward time: 24.22 ms\n",
            "frame_1728097294.5155132.jpg - Forward time: 23.39 ms\n",
            "frame_1728097296.5979767.jpg - Forward time: 36.85 ms\n",
            "frame_1728097298.6884751.jpg - Forward time: 42.16 ms\n",
            "frame_1728097300.7641978.jpg - Forward time: 43.03 ms\n",
            "frame_1728097302.8513896.jpg - Forward time: 32.37 ms\n",
            "frame_1728097304.9226253.jpg - Forward time: 23.15 ms\n",
            "frame_1728097307.0107243.jpg - Forward time: 23.82 ms\n",
            "frame_1728097309.1025863.jpg - Forward time: 25.73 ms\n",
            "frame_1728097311.165829.jpg - Forward time: 27.03 ms\n",
            "frame_1728097313.2615905.jpg - Forward time: 37.95 ms\n",
            "frame_1728097315.3525324.jpg - Forward time: 24.31 ms\n",
            "frame_1728097317.4511716.jpg - Forward time: 23.50 ms\n",
            "frame_1728097319.5312169.jpg - Forward time: 26.08 ms\n",
            "frame_1728097321.6103728.jpg - Forward time: 33.16 ms\n",
            "frame_1728097323.6933348.jpg - Forward time: 32.66 ms\n",
            "frame_1728097325.7817464.jpg - Forward time: 26.25 ms\n",
            "frame_1728097327.878606.jpg - Forward time: 29.30 ms\n",
            "frame_1728097329.957971.jpg - Forward time: 39.47 ms\n",
            "frame_1728097332.0400512.jpg - Forward time: 23.12 ms\n",
            "frame_1728097334.122568.jpg - Forward time: 23.93 ms\n",
            "frame_1728097336.2076685.jpg - Forward time: 25.84 ms\n",
            "frame_1728097338.289301.jpg - Forward time: 33.88 ms\n",
            "frame_1728097340.3711658.jpg - Forward time: 24.85 ms\n",
            "frame_1728097342.4532888.jpg - Forward time: 23.96 ms\n",
            "frame_1728097344.5274346.jpg - Forward time: 29.75 ms\n",
            "frame_1728097346.615021.jpg - Forward time: 42.23 ms\n",
            "Processing complete. Results saved in the specified output directory and CSV file.\n"
          ]
        }
      ],
      "source": [
        "test_csv = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Test/test.csv'\n",
        "LABEL_NAMES = ['person']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "img_path = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Dataset/0_Raw/2024-10-05/Image_Frames/session_1/2_person'\n",
        "selected_timestamps = load_img_data(img_path)\n",
        "\n",
        "# Prepare CSV file\n",
        "with open(test_csv, mode='w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow([\"Image\", \"Persons\", \"Average Confidence\"])\n",
        "\n",
        "    # For each selected timestamp, load the corresponding image and make predictions\n",
        "    for timestamp in selected_timestamps:\n",
        "        img_file = f\"frame_{timestamp}.jpg\"\n",
        "        path = os.path.join(img_path, img_file)\n",
        "        ori_img = cv2.imread(path)\n",
        "        if ori_img is None:\n",
        "            print(f\"Skipping file {img_file} (not an image)\")\n",
        "            continue\n",
        "\n",
        "        # Data preprocessing\n",
        "        res_img = cv2.resize(ori_img, (352, 352), interpolation=cv2.INTER_LINEAR)\n",
        "        img = res_img.reshape(1, 352, 352, 3)\n",
        "        img = torch.from_numpy(img.transpose(0, 3, 1, 2)).to(device).float() / 255.0\n",
        "\n",
        "        # Model inference\n",
        "        start = time.perf_counter()\n",
        "        preds = cv_model(img)\n",
        "        end = time.perf_counter()\n",
        "        inference_time = (end - start) * 1000.0\n",
        "        print(f\"{img_file} - Forward time: {inference_time:.2f} ms\")\n",
        "\n",
        "          # Post-process predictions\n",
        "        output = handel_preds(preds, device)\n",
        "        output_boxes = non_max_suppression(output, conf_thres=0.3, iou_thres=0.4)\n",
        "\n",
        "        h, w, _ = ori_img.shape\n",
        "        scale_h, scale_w = h / 352, w / 352\n",
        "\n",
        "        person_count = 0\n",
        "        confidence_scores = []\n",
        "\n",
        "        # Draw bounding boxes and collect predictions for persons\n",
        "        for box in output_boxes[0]:\n",
        "            box = box.tolist()\n",
        "            obj_score = box[4]\n",
        "            category = LABEL_NAMES[int(box[5])]\n",
        "\n",
        "            # Check if the detected object is a person\n",
        "            if category.lower() == \"person\":\n",
        "                person_count += 1\n",
        "                confidence_scores.append(obj_score)\n",
        "\n",
        "                x1, y1 = int(box[0] * scale_w), int(box[1] * scale_h)\n",
        "                x2, y2 = int(box[2] * scale_w), int(box[3] * scale_h)\n",
        "\n",
        "                cv2.rectangle(ori_img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "                cv2.putText(ori_img, f'{obj_score:.2f}', (x1, y1 - 5), 0, 0.7, (0, 255, 0), 2)\n",
        "                cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "          # Calculate average confidence score\n",
        "        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0\n",
        "\n",
        "          # Write result to CSV\n",
        "        csv_writer.writerow([img_file, person_count, f\"{avg_confidence:.2f}\"])\n",
        "\n",
        "print(\"Processing complete. Results saved in the specified output directory and CSV file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_csv = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Test/test.csv'\n",
        "test_df = pd.read_csv(test_csv)\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "VypwEOupsJL1",
        "outputId": "cab55106-fb35-4880-d39b-b142fe36a186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Image  Persons  Average Confidence\n",
              "0   frame_1728097171.6832385.jpg        2                1.00\n",
              "1   frame_1728097173.7763522.jpg        2                0.99\n",
              "2   frame_1728097175.8573422.jpg        2                1.00\n",
              "3   frame_1728097177.9508202.jpg        3                0.72\n",
              "4   frame_1728097180.0337336.jpg        2                0.98\n",
              "5   frame_1728097182.1125855.jpg        2                1.00\n",
              "6   frame_1728097184.1985004.jpg        2                1.00\n",
              "7   frame_1728097186.2712324.jpg        2                1.00\n",
              "8   frame_1728097188.3541796.jpg        2                0.88\n",
              "9   frame_1728097190.4391413.jpg        3                0.85\n",
              "10  frame_1728097192.5285933.jpg        2                1.00\n",
              "11  frame_1728097194.6059685.jpg        2                1.00\n",
              "12   frame_1728097196.701152.jpg        2                0.94\n",
              "13  frame_1728097198.7897072.jpg        2                0.96\n",
              "14  frame_1728097200.8785574.jpg        3                1.00\n",
              "15  frame_1728097202.9462562.jpg        3                0.93\n",
              "16   frame_1728097205.051112.jpg        2                1.00\n",
              "17  frame_1728097207.1356993.jpg        2                0.93\n",
              "18  frame_1728097209.2243829.jpg        2                0.98\n",
              "19  frame_1728097211.3018258.jpg        4                0.79"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b7c548-9b0b-4221-b10b-da9a4dc331ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Persons</th>\n",
              "      <th>Average Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_1728097171.6832385.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_1728097173.7763522.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_1728097175.8573422.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_1728097177.9508202.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_1728097180.0337336.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>frame_1728097182.1125855.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frame_1728097184.1985004.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>frame_1728097186.2712324.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>frame_1728097188.3541796.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>frame_1728097190.4391413.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>frame_1728097192.5285933.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>frame_1728097194.6059685.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>frame_1728097196.701152.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>frame_1728097198.7897072.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>frame_1728097200.8785574.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>frame_1728097202.9462562.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>frame_1728097205.051112.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>frame_1728097207.1356993.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>frame_1728097209.2243829.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>frame_1728097211.3018258.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b7c548-9b0b-4221-b10b-da9a4dc331ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21b7c548-9b0b-4221-b10b-da9a4dc331ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21b7c548-9b0b-4221-b10b-da9a4dc331ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9c69a73-b310-44d6-b737-520896543a3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c69a73-b310-44d6-b737-520896543a3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9c69a73-b310-44d6-b737-520896543a3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 85,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"frame_1728097334.122568.jpg\",\n          \"frame_1728097171.6832385.jpg\",\n          \"frame_1728097313.2615905.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Persons\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09176605256499451,\n        \"min\": 0.66,\n        \"max\": 1.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.93,\n          0.71,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions[:len(test_df)]\n",
        "rounded = np.round(predictions).astype(int)\n",
        "test_df['csi'] = rounded\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "id": "qUJ6BWTHBMqj",
        "outputId": "b56511a6-6b36-42fa-f9de-ae1dce6b3a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Image  Persons  Average Confidence  csi\n",
              "0   frame_1728097171.6832385.jpg        2                1.00    2\n",
              "1   frame_1728097173.7763522.jpg        2                0.99    2\n",
              "2   frame_1728097175.8573422.jpg        2                1.00    0\n",
              "3   frame_1728097177.9508202.jpg        3                0.72    1\n",
              "4   frame_1728097180.0337336.jpg        2                0.98    1\n",
              "5   frame_1728097182.1125855.jpg        2                1.00    3\n",
              "6   frame_1728097184.1985004.jpg        2                1.00    3\n",
              "7   frame_1728097186.2712324.jpg        2                1.00    3\n",
              "8   frame_1728097188.3541796.jpg        2                0.88    2\n",
              "9   frame_1728097190.4391413.jpg        3                0.85    1\n",
              "10  frame_1728097192.5285933.jpg        2                1.00    1\n",
              "11  frame_1728097194.6059685.jpg        2                1.00    2\n",
              "12   frame_1728097196.701152.jpg        2                0.94    2\n",
              "13  frame_1728097198.7897072.jpg        2                0.96    2\n",
              "14  frame_1728097200.8785574.jpg        3                1.00    2\n",
              "15  frame_1728097202.9462562.jpg        3                0.93    1\n",
              "16   frame_1728097205.051112.jpg        2                1.00    2\n",
              "17  frame_1728097207.1356993.jpg        2                0.93    2\n",
              "18  frame_1728097209.2243829.jpg        2                0.98    1\n",
              "19  frame_1728097211.3018258.jpg        4                0.79    3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e716258-8988-4158-bbff-a191a8a62286\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Persons</th>\n",
              "      <th>Average Confidence</th>\n",
              "      <th>csi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_1728097171.6832385.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_1728097173.7763522.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.99</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_1728097175.8573422.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_1728097177.9508202.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_1728097180.0337336.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>frame_1728097182.1125855.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frame_1728097184.1985004.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>frame_1728097186.2712324.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>frame_1728097188.3541796.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.88</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>frame_1728097190.4391413.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>frame_1728097192.5285933.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>frame_1728097194.6059685.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>frame_1728097196.701152.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.94</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>frame_1728097198.7897072.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.96</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>frame_1728097200.8785574.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>frame_1728097202.9462562.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>frame_1728097205.051112.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>frame_1728097207.1356993.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.93</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>frame_1728097209.2243829.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>frame_1728097211.3018258.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.79</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e716258-8988-4158-bbff-a191a8a62286')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e716258-8988-4158-bbff-a191a8a62286 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e716258-8988-4158-bbff-a191a8a62286');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a43bfdb-88ef-4f13-9a6c-3e7741edd5cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a43bfdb-88ef-4f13-9a6c-3e7741edd5cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a43bfdb-88ef-4f13-9a6c-3e7741edd5cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 85,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"frame_1728097334.122568.jpg\",\n          \"frame_1728097171.6832385.jpg\",\n          \"frame_1728097313.2615905.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Persons\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09176605256499451,\n        \"min\": 0.66,\n        \"max\": 1.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.93,\n          0.71,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"csi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = test_df[test_df['Average Confidence'] < 0.8]\n",
        "\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "bXnc66lLB-sV",
        "outputId": "54e668e7-3240-4df4-b57a-8e6c06344d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Image  Persons  Average Confidence  csi\n",
            "3   frame_1728097177.9508202.jpg        3                0.72    1\n",
            "19  frame_1728097211.3018258.jpg        4                0.79    3\n",
            "35    frame_1728097244.57866.jpg        4                0.79    3\n",
            "39  frame_1728097252.8922708.jpg        3                0.79    2\n",
            "44   frame_1728097263.301632.jpg        4                0.66    2\n",
            "49  frame_1728097273.7192578.jpg        3                0.72    3\n",
            "54  frame_1728097284.1123533.jpg        3                0.77    2\n",
            "61  frame_1728097298.6884751.jpg        4                0.71    3\n",
            "63  frame_1728097302.8513896.jpg        2                0.73    2\n",
            "65  frame_1728097307.0107243.jpg        4                0.75    3\n",
            "66  frame_1728097309.1025863.jpg        3                0.77    2\n",
            "79  frame_1728097336.2076685.jpg        4                0.79    1\n",
            "80   frame_1728097338.289301.jpg        3                0.77    2\n",
            "84   frame_1728097346.615021.jpg        3                0.78    2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and the true value is 2\n",
        "true_value = 2\n",
        "\n",
        "# Filter for rows where both columns A and B are not equal to the true value\n",
        "wrong_instances = filtered_df[(filtered_df['Persons'] != true_value) & (filtered_df['csi'] != true_value)]\n",
        "\n",
        "# Count the number of such instances\n",
        "wrong_count = len(wrong_instances)\n",
        "\n",
        "print(\"Number of instances where both A and B are incorrect:\", wrong_count)\n",
        "print(\"Rows where both A and B are incorrect:\\n\", wrong_instances)"
      ],
      "metadata": {
        "id": "gLQJibheCXD4",
        "outputId": "d2d5b01c-0cce-4266-ac4f-de0681e89826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances where both A and B are incorrect: 7\n",
            "Rows where both A and B are incorrect:\n",
            "                            Image  Persons  Average Confidence  csi\n",
            "3   frame_1728097177.9508202.jpg        3                0.72    1\n",
            "19  frame_1728097211.3018258.jpg        4                0.79    3\n",
            "35    frame_1728097244.57866.jpg        4                0.79    3\n",
            "49  frame_1728097273.7192578.jpg        3                0.72    3\n",
            "61  frame_1728097298.6884751.jpg        4                0.71    3\n",
            "65  frame_1728097307.0107243.jpg        4                0.75    3\n",
            "79  frame_1728097336.2076685.jpg        4                0.79    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and the true value is 2\n",
        "true_value = 2\n",
        "\n",
        "# Filter for rows where A is incorrect and B is correct\n",
        "a_wrong_b_right = filtered_df[(filtered_df['Persons'] != true_value) & (filtered_df['csi'] == true_value)]\n",
        "\n",
        "# Count the number of such instances\n",
        "a_wrong_b_right_count = len(a_wrong_b_right)\n",
        "\n",
        "print(\"Number of instances where A is incorrect but B is correct:\", a_wrong_b_right_count)\n",
        "print(\"Rows where A is incorrect but B is correct:\\n\", a_wrong_b_right)\n"
      ],
      "metadata": {
        "id": "GlmTYyMeCoKp",
        "outputId": "6ce4f4b1-1d7a-492e-f07a-090def548682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances where A is incorrect but B is correct: 6\n",
            "Rows where A is incorrect but B is correct:\n",
            "                            Image  Persons  Average Confidence  csi\n",
            "39  frame_1728097252.8922708.jpg        3                0.79    2\n",
            "44   frame_1728097263.301632.jpg        4                0.66    2\n",
            "54  frame_1728097284.1123533.jpg        3                0.77    2\n",
            "66  frame_1728097309.1025863.jpg        3                0.77    2\n",
            "80   frame_1728097338.289301.jpg        3                0.77    2\n",
            "84   frame_1728097346.615021.jpg        3                0.78    2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2024-09-28"
      ],
      "metadata": {
        "id": "3x74o0YJDQla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    weights_path = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Models/yolof2-v4/yolofv2-nano-190-epoch-0.945714ap-model.pth'\n",
        "    img_path = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Dataset/1_Processed/2024-09-28/Image_Frames/session_1/5_person'\n",
        "\n",
        "    image_filenames = os.listdir(img_path)\n",
        "\n",
        "    # Extract timestamps from filenames and sort them\n",
        "    timestamps = []\n",
        "    for filename in image_filenames:\n",
        "      timestamp_str = filename.replace(\"frame_\", \"\").replace(\".jpg\", \"\")\n",
        "      timestamps.append(float(timestamp_str))\n",
        "\n",
        "    timestamps = sorted(timestamps)\n",
        "\n",
        "    # Select images with a 2-second interval\n",
        "    selected_timestamps = []\n",
        "    previous_timestamp = None\n",
        "    for timestamp in timestamps:\n",
        "        if previous_timestamp is None or timestamp - previous_timestamp >= 2:\n",
        "            selected_timestamps.append(timestamp)\n",
        "            previous_timestamp = timestamp\n",
        "    print(len(selected_timestamps))\n",
        "\n",
        "    # Load the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Detector(1, 3, True).to(device)\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "    model.eval()\n",
        "    test_csv = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Test/test_dark.csv'\n",
        "    # Load label names\n",
        "    LABEL_NAMES = ['person']\n",
        "\n",
        "    # Prepare CSV file\n",
        "    with open(test_csv, mode='w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow([\"Image\", \"Persons\", \"Average Confidence\"])\n",
        "\n",
        "       # For each selected timestamp, load the corresponding image and make predictions\n",
        "        for timestamp in selected_timestamps:\n",
        "            img_file = f\"frame_{timestamp}.jpg\"\n",
        "            path = os.path.join(img_path, img_file)\n",
        "            ori_img = cv2.imread(path)\n",
        "            if ori_img is None:\n",
        "                print(f\"Skipping file {img_file} (not an image)\")\n",
        "                continue\n",
        "\n",
        "            # Data preprocessing\n",
        "            res_img = cv2.resize(ori_img, (352, 352), interpolation=cv2.INTER_LINEAR)\n",
        "            img = res_img.reshape(1, 352, 352, 3)\n",
        "            img = torch.from_numpy(img.transpose(0, 3, 1, 2)).to(device).float() / 255.0\n",
        "\n",
        "            # Model inference\n",
        "            start = time.perf_counter()\n",
        "            preds = model(img)\n",
        "            end = time.perf_counter()\n",
        "            inference_time = (end - start) * 1000.0\n",
        "            print(f\"{img_file} - Forward time: {inference_time:.2f} ms\")\n",
        "\n",
        "             # Post-process predictions\n",
        "            output = handel_preds(preds, device)\n",
        "            output_boxes = non_max_suppression(output, conf_thres=0.3, iou_thres=0.4)\n",
        "\n",
        "            h, w, _ = ori_img.shape\n",
        "            scale_h, scale_w = h / 352, w / 352\n",
        "\n",
        "            person_count = 0\n",
        "            confidence_scores = []\n",
        "\n",
        "            # Draw bounding boxes and collect predictions for persons\n",
        "            for box in output_boxes[0]:\n",
        "                box = box.tolist()\n",
        "                obj_score = box[4]\n",
        "                category = LABEL_NAMES[int(box[5])]\n",
        "\n",
        "                # Check if the detected object is a person\n",
        "                if category.lower() == \"person\":\n",
        "                    person_count += 1\n",
        "                    confidence_scores.append(obj_score)\n",
        "\n",
        "                    x1, y1 = int(box[0] * scale_w), int(box[1] * scale_h)\n",
        "                    x2, y2 = int(box[2] * scale_w), int(box[3] * scale_h)\n",
        "\n",
        "                    cv2.rectangle(ori_img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "                    cv2.putText(ori_img, f'{obj_score:.2f}', (x1, y1 - 5), 0, 0.7, (0, 255, 0), 2)\n",
        "                    cv2.putText(ori_img, category, (x1, y1 - 25), 0, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "             # Calculate average confidence score\n",
        "            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0\n",
        "\n",
        "             # Write result to CSV\n",
        "            csv_writer.writerow([img_file, person_count, f\"{avg_confidence:.2f}\"])\n",
        "\n",
        "    print(\"Processing complete. Results saved in the specified output directory and CSV file.\")\n"
      ],
      "metadata": {
        "id": "Zdl-BCjyDwt0",
        "outputId": "0d37ca9d-6b88-4939-f790-297721ecb717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85\n",
            "load param...\n",
            "frame_1727491800.4745471.jpg - Forward time: 31.48 ms\n",
            "frame_1727491802.474872.jpg - Forward time: 23.45 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-942279c3a05e>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frame_1727491804.4932518.jpg - Forward time: 28.17 ms\n",
            "frame_1727491806.5411992.jpg - Forward time: 30.03 ms\n",
            "frame_1727491808.6285856.jpg - Forward time: 24.14 ms\n",
            "frame_1727491810.6985395.jpg - Forward time: 29.03 ms\n",
            "frame_1727491812.7572093.jpg - Forward time: 24.18 ms\n",
            "frame_1727491814.8437064.jpg - Forward time: 27.74 ms\n",
            "frame_1727491816.9239798.jpg - Forward time: 22.65 ms\n",
            "frame_1727491819.0106845.jpg - Forward time: 23.18 ms\n",
            "frame_1727491821.0938544.jpg - Forward time: 23.32 ms\n",
            "frame_1727491823.1606328.jpg - Forward time: 23.53 ms\n",
            "frame_1727491825.2532883.jpg - Forward time: 23.56 ms\n",
            "frame_1727491827.3364673.jpg - Forward time: 27.48 ms\n",
            "frame_1727491829.421625.jpg - Forward time: 85.70 ms\n",
            "frame_1727491831.5003645.jpg - Forward time: 23.67 ms\n",
            "frame_1727491833.5941215.jpg - Forward time: 25.01 ms\n",
            "frame_1727491835.6751053.jpg - Forward time: 24.46 ms\n",
            "frame_1727491837.7504373.jpg - Forward time: 24.98 ms\n",
            "frame_1727491839.8116074.jpg - Forward time: 24.89 ms\n",
            "frame_1727491841.8866038.jpg - Forward time: 24.07 ms\n",
            "frame_1727491844.2069085.jpg - Forward time: 25.04 ms\n",
            "frame_1727491846.293151.jpg - Forward time: 24.11 ms\n",
            "frame_1727491848.3778746.jpg - Forward time: 28.06 ms\n",
            "frame_1727491850.455049.jpg - Forward time: 25.19 ms\n",
            "frame_1727491852.529991.jpg - Forward time: 24.09 ms\n",
            "frame_1727491854.584155.jpg - Forward time: 23.54 ms\n",
            "frame_1727491856.6560283.jpg - Forward time: 23.55 ms\n",
            "frame_1727491858.7289243.jpg - Forward time: 24.20 ms\n",
            "frame_1727491860.82823.jpg - Forward time: 24.86 ms\n",
            "frame_1727491862.8932705.jpg - Forward time: 24.00 ms\n",
            "frame_1727491864.977788.jpg - Forward time: 23.26 ms\n",
            "frame_1727491867.162404.jpg - Forward time: 25.29 ms\n",
            "frame_1727491869.2592788.jpg - Forward time: 23.62 ms\n",
            "frame_1727491871.3200364.jpg - Forward time: 23.98 ms\n",
            "frame_1727491873.516343.jpg - Forward time: 22.72 ms\n",
            "frame_1727491875.6064765.jpg - Forward time: 22.95 ms\n",
            "frame_1727491877.668693.jpg - Forward time: 27.14 ms\n",
            "frame_1727491879.7345643.jpg - Forward time: 26.06 ms\n",
            "frame_1727491881.811666.jpg - Forward time: 27.57 ms\n",
            "frame_1727491883.9016747.jpg - Forward time: 23.91 ms\n",
            "frame_1727491885.9930747.jpg - Forward time: 23.48 ms\n",
            "frame_1727491888.0749617.jpg - Forward time: 23.49 ms\n",
            "frame_1727491890.1631296.jpg - Forward time: 24.40 ms\n",
            "frame_1727491892.2321782.jpg - Forward time: 23.63 ms\n",
            "frame_1727491894.3105667.jpg - Forward time: 26.49 ms\n",
            "frame_1727491896.3911943.jpg - Forward time: 24.13 ms\n",
            "frame_1727491898.4541156.jpg - Forward time: 23.53 ms\n",
            "frame_1727491900.5414493.jpg - Forward time: 28.98 ms\n",
            "frame_1727491902.6177642.jpg - Forward time: 25.17 ms\n",
            "frame_1727491904.689093.jpg - Forward time: 27.41 ms\n",
            "frame_1727491906.7661397.jpg - Forward time: 24.44 ms\n",
            "frame_1727491908.856939.jpg - Forward time: 23.54 ms\n",
            "frame_1727491910.9278097.jpg - Forward time: 24.83 ms\n",
            "frame_1727491913.0040035.jpg - Forward time: 25.53 ms\n",
            "frame_1727491915.0925841.jpg - Forward time: 27.10 ms\n",
            "frame_1727491917.1544533.jpg - Forward time: 25.62 ms\n",
            "frame_1727491919.2186701.jpg - Forward time: 23.82 ms\n",
            "frame_1727491921.2969673.jpg - Forward time: 23.24 ms\n",
            "frame_1727491923.3817234.jpg - Forward time: 27.76 ms\n",
            "frame_1727491925.5482996.jpg - Forward time: 23.73 ms\n",
            "frame_1727491927.6098273.jpg - Forward time: 24.86 ms\n",
            "frame_1727491929.793055.jpg - Forward time: 24.39 ms\n",
            "frame_1727491931.8503358.jpg - Forward time: 24.23 ms\n",
            "frame_1727491933.914587.jpg - Forward time: 32.69 ms\n",
            "frame_1727491936.0177083.jpg - Forward time: 23.82 ms\n",
            "frame_1727491938.216471.jpg - Forward time: 23.92 ms\n",
            "frame_1727491940.2956486.jpg - Forward time: 27.00 ms\n",
            "frame_1727491942.5077975.jpg - Forward time: 24.19 ms\n",
            "frame_1727491944.5972867.jpg - Forward time: 27.46 ms\n",
            "frame_1727491946.6862519.jpg - Forward time: 24.34 ms\n",
            "frame_1727491948.7794135.jpg - Forward time: 24.23 ms\n",
            "frame_1727491950.882804.jpg - Forward time: 24.50 ms\n",
            "frame_1727491952.963242.jpg - Forward time: 31.55 ms\n",
            "frame_1727491955.0628746.jpg - Forward time: 25.08 ms\n",
            "frame_1727491957.137366.jpg - Forward time: 23.85 ms\n",
            "frame_1727491959.2182205.jpg - Forward time: 26.08 ms\n",
            "frame_1727491961.295107.jpg - Forward time: 29.11 ms\n",
            "frame_1727491963.3609395.jpg - Forward time: 23.80 ms\n",
            "frame_1727491965.5605505.jpg - Forward time: 24.76 ms\n",
            "frame_1727491967.646424.jpg - Forward time: 24.54 ms\n",
            "frame_1727491969.7260613.jpg - Forward time: 26.23 ms\n",
            "frame_1727491971.80172.jpg - Forward time: 24.50 ms\n",
            "frame_1727491973.8964338.jpg - Forward time: 23.81 ms\n",
            "frame_1727491976.0912206.jpg - Forward time: 25.10 ms\n",
            "Processing complete. Results saved in the specified output directory and CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dark_csv = '/content/drive/MyDrive/UIT/UIT_Graduation_Thesis/Test/test_dark.csv'\n",
        "test_dark = pd.read_csv(test_dark_csv)\n",
        "test_dark.head(20)"
      ],
      "metadata": {
        "id": "QfBpznBdEbYw",
        "outputId": "00dcf6c2-efdd-4985-f422-96c6fc4b2cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Image  Persons  Average Confidence\n",
              "0   frame_1727491800.4745471.jpg        5                0.99\n",
              "1    frame_1727491802.474872.jpg        3                1.00\n",
              "2   frame_1727491804.4932518.jpg        4                1.00\n",
              "3   frame_1727491806.5411992.jpg        6                0.88\n",
              "4   frame_1727491808.6285856.jpg        7                0.91\n",
              "5   frame_1727491810.6985395.jpg        6                0.93\n",
              "6   frame_1727491812.7572093.jpg        6                0.97\n",
              "7   frame_1727491814.8437064.jpg        3                0.98\n",
              "8   frame_1727491816.9239798.jpg        5                0.94\n",
              "9   frame_1727491819.0106845.jpg        6                0.87\n",
              "10  frame_1727491821.0938544.jpg        9                0.86\n",
              "11  frame_1727491823.1606328.jpg        6                0.81\n",
              "12  frame_1727491825.2532883.jpg        4                0.86\n",
              "13  frame_1727491827.3364673.jpg        6                0.94\n",
              "14   frame_1727491829.421625.jpg        6                0.94\n",
              "15  frame_1727491831.5003645.jpg        7                0.91\n",
              "16  frame_1727491833.5941215.jpg        5                0.93\n",
              "17  frame_1727491835.6751053.jpg        4                0.90\n",
              "18  frame_1727491837.7504373.jpg        4                0.83\n",
              "19  frame_1727491839.8116074.jpg        6                0.93"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7472797-1f59-46e4-973b-8e63e37c763d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Persons</th>\n",
              "      <th>Average Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_1727491800.4745471.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_1727491802.474872.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_1727491804.4932518.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_1727491806.5411992.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_1727491808.6285856.jpg</td>\n",
              "      <td>7</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>frame_1727491810.6985395.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frame_1727491812.7572093.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>frame_1727491814.8437064.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>frame_1727491816.9239798.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>frame_1727491819.0106845.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>frame_1727491821.0938544.jpg</td>\n",
              "      <td>9</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>frame_1727491823.1606328.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>frame_1727491825.2532883.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>frame_1727491827.3364673.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>frame_1727491829.421625.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>frame_1727491831.5003645.jpg</td>\n",
              "      <td>7</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>frame_1727491833.5941215.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>frame_1727491835.6751053.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>frame_1727491837.7504373.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>frame_1727491839.8116074.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7472797-1f59-46e4-973b-8e63e37c763d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7472797-1f59-46e4-973b-8e63e37c763d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7472797-1f59-46e4-973b-8e63e37c763d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a83e8e09-93d7-40a9-b62b-4e08aa7ccd26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a83e8e09-93d7-40a9-b62b-4e08aa7ccd26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a83e8e09-93d7-40a9-b62b-4e08aa7ccd26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_dark",
              "summary": "{\n  \"name\": \"test_dark\",\n  \"rows\": 85,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"frame_1727491963.3609395.jpg\",\n          \"frame_1727491800.4745471.jpg\",\n          \"frame_1727491942.5077975.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Persons\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5,\n          3,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average Confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07175705979380773,\n        \"min\": 0.73,\n        \"max\": 1.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.87,\n          0.89,\n          0.99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}